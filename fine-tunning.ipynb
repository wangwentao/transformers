{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (C:/Users/wentao/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|██████████| 3/3 [00:00<00:00, 336.32it/s]\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\wentao\\.cache\\huggingface\\datasets\\glue\\mrpc\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-aaf838c3ea7173c0.arrow\n",
      "Loading cached processed dataset at C:\\Users\\wentao\\.cache\\huggingface\\datasets\\glue\\mrpc\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-8b83d0a3bf0e5334.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 3668\n    })\n    validation: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 408\n    })\n    test: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 1725\n    })\n})"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 3668\n})"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\"test-trainer\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/1377 : < :, Epoch 0.00/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=1377, training_loss=0.4782188819990525, metrics={'train_runtime': 247.9399, 'train_samples_per_second': 44.382, 'train_steps_per_second': 5.554, 'total_flos': 406183858377360.0, 'train_loss': 0.4782188819990525, 'epoch': 3.0})"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/51 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408, 2) (408,)\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n       0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n       1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n       1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n       0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1], dtype=int64)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "preds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-3.0577843 ,  2.8627203 ],\n       [ 2.0907295 , -1.2846566 ],\n       [ 1.7277778 , -1.0828229 ],\n       [-2.9677072 ,  2.883642  ],\n       [ 2.2881207 , -1.3895211 ],\n       [-2.6766088 ,  2.7422392 ],\n       [-2.2058039 ,  2.3149145 ],\n       [-2.950029  ,  2.8857083 ],\n       [-2.3438742 ,  2.4825504 ],\n       [-3.1045465 ,  2.611225  ],\n       [-3.0698988 ,  2.6766682 ],\n       [ 1.9509966 , -1.2285905 ],\n       [ 2.2831323 , -1.3920159 ],\n       [-2.062544  ,  2.1896796 ],\n       [-3.0780234 ,  2.6598167 ],\n       [ 0.93330294, -0.5582105 ],\n       [-3.104889  ,  2.6801832 ],\n       [ 2.2820888 , -1.3970805 ],\n       [-3.0895574 ,  2.748747  ],\n       [ 2.0492036 , -1.2452615 ],\n       [ 2.2880082 , -1.4020364 ],\n       [-2.308605  ,  2.4494615 ],\n       [ 2.1889648 , -1.3472853 ],\n       [-3.0342398 ,  2.825386  ],\n       [-2.9411917 ,  2.8680875 ],\n       [-2.3846462 ,  2.5178728 ],\n       [ 2.1454933 , -1.3313525 ],\n       [-3.0533857 ,  2.646034  ],\n       [-1.9395419 ,  2.0499833 ],\n       [-3.0691626 ,  2.8159156 ],\n       [ 1.9338945 , -1.22879   ],\n       [-3.060346  ,  2.6860247 ],\n       [-2.6478202 ,  2.7577486 ],\n       [-2.8297794 ,  2.8227875 ],\n       [-2.6239836 ,  2.7373548 ],\n       [-2.5340855 ,  2.6280234 ],\n       [ 2.0932202 , -1.3023763 ],\n       [ 2.231786  , -1.3865818 ],\n       [-2.344729  ,  2.4558585 ],\n       [-3.0625875 ,  2.6837943 ],\n       [ 2.1117954 , -1.2971679 ],\n       [-2.27572   ,  2.4721224 ],\n       [-1.1926842 ,  1.1949866 ],\n       [ 2.1547585 , -1.3510708 ],\n       [ 2.1956677 , -1.334826  ],\n       [-2.6391845 ,  2.7467759 ],\n       [-2.710137  ,  2.8114552 ],\n       [ 2.2152746 , -1.3824167 ],\n       [-3.0825865 ,  2.73706   ],\n       [-2.689533  ,  2.7871773 ],\n       [-1.9033515 ,  1.9508007 ],\n       [-1.6092219 ,  1.6201389 ],\n       [-3.100678  ,  2.6619885 ],\n       [-3.044941  ,  2.8298593 ],\n       [-3.0702128 ,  2.8561652 ],\n       [-2.0652187 ,  2.2065222 ],\n       [ 0.39998165, -0.08986334],\n       [-3.0660613 ,  2.8299525 ],\n       [-3.0833204 ,  2.7724867 ],\n       [-2.3799086 ,  2.5613973 ],\n       [-2.8220513 ,  2.8170638 ],\n       [ 1.9157672 , -1.2201021 ],\n       [-3.0746038 ,  2.8050833 ],\n       [-2.6676464 ,  2.7636793 ],\n       [-1.1938927 ,  1.2829297 ],\n       [ 2.1418195 , -1.3037997 ],\n       [-3.0701473 ,  2.7024624 ],\n       [-3.072001  ,  2.691337  ],\n       [-2.8433614 ,  2.8318563 ],\n       [-2.9231868 ,  2.8570018 ],\n       [-3.0038834 ,  2.8905747 ],\n       [-1.4963889 ,  1.5224978 ],\n       [-3.056968  ,  2.8118103 ],\n       [-1.9637595 ,  2.1236386 ],\n       [-1.9081908 ,  1.9657918 ],\n       [-2.1804025 ,  2.3274827 ],\n       [-2.6879468 ,  2.7703774 ],\n       [-3.051409  ,  2.697874  ],\n       [-3.0560725 ,  2.8332918 ],\n       [-2.1832242 ,  2.3196373 ],\n       [-1.9381869 ,  1.974637  ],\n       [-1.0578402 ,  1.191946  ],\n       [-3.0534632 ,  2.785424  ],\n       [-1.9589264 ,  2.0552952 ],\n       [-3.0571034 ,  2.759118  ],\n       [ 0.37406233, -0.0667449 ],\n       [-2.4748738 ,  2.630037  ],\n       [-2.3528087 ,  2.5024338 ],\n       [-3.080298  ,  2.7906206 ],\n       [-3.0923307 ,  2.6321213 ],\n       [-1.0179358 ,  1.1162739 ],\n       [-3.0585544 ,  2.7684386 ],\n       [-2.2193882 ,  2.356243  ],\n       [-3.036366  ,  2.759658  ],\n       [-3.0359044 ,  2.888443  ],\n       [-3.099627  ,  2.6462486 ],\n       [ 2.0220346 , -1.251774  ],\n       [-2.1880655 ,  2.3282516 ],\n       [-1.9957216 ,  2.0816598 ],\n       [-3.002428  ,  2.8665526 ],\n       [-2.9241316 ,  2.865084  ],\n       [-2.132064  ,  2.273417  ],\n       [-2.344786  ,  2.5130687 ],\n       [-2.9692004 ,  2.9055161 ],\n       [-2.7209485 ,  2.791251  ],\n       [-2.8319807 ,  2.857959  ],\n       [-0.2032288 ,  0.37734506],\n       [ 1.2546822 , -0.7858161 ],\n       [ 2.1811314 , -1.3304074 ],\n       [-2.8844795 ,  2.8621044 ],\n       [ 0.14581165,  0.15370989],\n       [-2.9324725 ,  2.8895261 ],\n       [-3.0507035 ,  2.6600118 ],\n       [-3.0757706 ,  2.6355093 ],\n       [-1.8623513 ,  1.9425244 ],\n       [ 0.7463769 , -0.4073417 ],\n       [-2.4362707 ,  2.6101964 ],\n       [-2.9620805 ,  2.8995104 ],\n       [-3.0734975 ,  2.6384804 ],\n       [-3.0562353 ,  2.8613777 ],\n       [-2.9527438 ,  2.8311718 ],\n       [-1.1234348 ,  1.1786249 ],\n       [ 2.1910317 , -1.3705662 ],\n       [-2.8621223 ,  2.8553994 ],\n       [-3.1016378 ,  2.7229404 ],\n       [-2.8467264 ,  2.840835  ],\n       [-3.0171735 ,  2.8683317 ],\n       [ 2.2571576 , -1.3908064 ],\n       [-3.06211   ,  2.6469553 ],\n       [-3.0082026 ,  2.870567  ],\n       [-2.0760596 ,  2.1606762 ],\n       [-2.2001255 ,  2.3128748 ],\n       [-2.4892728 ,  2.5803714 ],\n       [ 2.109695  , -1.3268448 ],\n       [-2.1152003 ,  2.2326362 ],\n       [-3.0078943 ,  2.8718207 ],\n       [-1.4154236 ,  1.4542453 ],\n       [ 2.1733556 , -1.3287574 ],\n       [-3.0854177 ,  2.697717  ],\n       [-2.913282  ,  2.850315  ],\n       [-3.076707  ,  2.776616  ],\n       [ 0.21298492,  0.01571853],\n       [ 2.3307838 , -1.4458894 ],\n       [-2.2977047 ,  2.3984609 ],\n       [ 2.2863538 , -1.4008087 ],\n       [ 0.99627084, -0.5807552 ],\n       [-3.0634217 ,  2.6965237 ],\n       [-0.38352838,  0.5110218 ],\n       [-0.25930712,  0.4516647 ],\n       [-2.0339646 ,  2.1268282 ],\n       [ 2.192487  , -1.362411  ],\n       [-2.8875816 ,  2.8594875 ],\n       [-2.226657  ,  2.3573205 ],\n       [-3.0684092 ,  2.725197  ],\n       [-2.8835125 ,  2.8995407 ],\n       [-3.0185452 ,  2.8699117 ],\n       [-2.9614294 ,  2.8804402 ],\n       [-1.3191304 ,  1.356339  ],\n       [ 1.1997685 , -0.71582633],\n       [-1.7588363 ,  1.7993301 ],\n       [-2.1083546 ,  2.2524664 ],\n       [-2.8552585 ,  2.8827603 ],\n       [-3.0724244 ,  2.6729581 ],\n       [-2.1909373 ,  2.3140976 ],\n       [-2.9085271 ,  2.858502  ],\n       [-3.0337536 ,  2.8418114 ],\n       [-2.1896157 ,  2.3904102 ],\n       [ 2.1021144 , -1.2959921 ],\n       [-2.3555882 ,  2.4982991 ],\n       [ 1.8033367 , -1.177518  ],\n       [-1.9418488 ,  1.9440553 ],\n       [-2.9391692 ,  2.8534238 ],\n       [-1.2359486 ,  1.3593664 ],\n       [-2.8425014 ,  2.8770573 ],\n       [-2.4722784 ,  2.6387603 ],\n       [-2.9739342 ,  2.8600686 ],\n       [-0.32542053,  0.51169235],\n       [ 1.8362906 , -1.1121484 ],\n       [-2.953057  ,  2.8915486 ],\n       [-3.1108978 ,  2.7541554 ],\n       [-2.4883575 ,  2.6626072 ],\n       [-2.384561  ,  2.4603336 ],\n       [-3.0493786 ,  2.8001487 ],\n       [-3.0865276 ,  2.7794702 ],\n       [-2.6035779 ,  2.6835515 ],\n       [-2.7612143 ,  2.8064392 ],\n       [ 2.0905688 , -1.3021002 ],\n       [-1.8791239 ,  1.9529002 ],\n       [ 2.261048  , -1.3721945 ],\n       [-3.0147736 ,  2.8283668 ],\n       [-3.0912716 ,  2.8142874 ],\n       [ 2.1013057 , -1.3415176 ],\n       [ 1.960921  , -1.2065933 ],\n       [-3.103307  ,  2.6892703 ],\n       [-1.9438453 ,  2.0018551 ],\n       [-2.2729232 ,  2.4219708 ],\n       [-3.024042  ,  2.8479247 ],\n       [-1.5427927 ,  1.5268719 ],\n       [-1.910317  ,  2.002289  ],\n       [-2.299428  ,  2.5023506 ],\n       [-3.0065775 ,  2.8278494 ],\n       [-2.9234457 ,  2.8728178 ],\n       [ 2.0328913 , -1.2562678 ],\n       [-3.0708356 ,  2.7999144 ],\n       [-2.2698033 ,  2.472517  ],\n       [ 2.1963496 , -1.3208393 ],\n       [-2.4302216 ,  2.5688872 ],\n       [-1.9288158 ,  1.9806511 ],\n       [ 1.6269072 , -0.9748643 ],\n       [-2.4939632 ,  2.6041548 ],\n       [ 1.7117833 , -1.0556767 ],\n       [-3.0544693 ,  2.7200625 ],\n       [ 2.1431887 , -1.3054942 ],\n       [ 1.9844007 , -1.238083  ],\n       [-2.9208467 ,  2.8399782 ],\n       [-3.1032882 ,  2.7140121 ],\n       [-2.7349277 ,  2.7463806 ],\n       [-2.345562  ,  2.480954  ],\n       [ 2.2033043 , -1.3416822 ],\n       [-2.6273682 ,  2.7108717 ],\n       [-2.51353   ,  2.6541538 ],\n       [-2.9507163 ,  2.8998997 ],\n       [-2.7322273 ,  2.8098743 ],\n       [ 2.2246    , -1.3320618 ],\n       [-3.0724869 ,  2.7693312 ],\n       [-3.0237455 ,  2.8419209 ],\n       [-3.078222  ,  2.8170562 ],\n       [-2.603429  ,  2.7220256 ],\n       [-2.2885914 ,  2.4837587 ],\n       [-2.1229985 ,  2.2648683 ],\n       [-2.5190418 ,  2.6347609 ],\n       [-2.858533  ,  2.817076  ],\n       [ 1.6977953 , -1.0273055 ],\n       [ 1.8229818 , -1.1630231 ],\n       [ 2.2246053 , -1.3509626 ],\n       [-2.0225918 ,  2.1528254 ],\n       [ 1.7210469 , -1.0841593 ],\n       [-1.5848676 ,  1.6146954 ],\n       [-2.0688317 ,  2.1830304 ],\n       [-1.3632836 ,  1.3547173 ],\n       [-2.6558428 ,  2.7499435 ],\n       [ 2.2542458 , -1.3896334 ],\n       [-0.66085   ,  0.7677654 ],\n       [-1.8653266 ,  1.8687034 ],\n       [-3.0602384 ,  2.8596222 ],\n       [-3.0700772 ,  2.7418485 ],\n       [-2.2696948 ,  2.3837636 ],\n       [-2.340165  ,  2.4692776 ],\n       [-2.978845  ,  2.8379908 ],\n       [-2.840641  ,  2.8410752 ],\n       [-2.2523758 ,  2.3587973 ],\n       [ 1.6158128 , -0.9687965 ],\n       [ 1.6518499 , -1.0181012 ],\n       [-0.22816771,  0.4112371 ],\n       [ 1.9865655 , -1.2132348 ],\n       [ 2.3042135 , -1.4045419 ],\n       [-2.3968487 ,  2.5520759 ],\n       [-2.081169  ,  2.2096815 ],\n       [-2.7376227 ,  2.8115678 ],\n       [-1.7742898 ,  1.7729504 ],\n       [-2.2704585 ,  2.4722593 ],\n       [-3.036028  ,  2.8635962 ],\n       [-2.9534466 ,  2.8514564 ],\n       [-1.8939389 ,  1.9878057 ],\n       [-2.0819867 ,  2.1912503 ],\n       [ 1.9102637 , -1.1817468 ],\n       [-2.0928376 ,  2.2566411 ],\n       [ 2.2484112 , -1.3965058 ],\n       [ 2.2367504 , -1.356836  ],\n       [-2.5195684 ,  2.6211126 ],\n       [ 2.0888057 , -1.299275  ],\n       [-3.08109   ,  2.827035  ],\n       [-3.086039  ,  2.7579565 ],\n       [-3.0153348 ,  2.8826525 ],\n       [-3.0932322 ,  2.7595463 ],\n       [-3.042775  ,  2.8601007 ],\n       [-2.7836423 ,  2.7681096 ],\n       [-0.26064023,  0.495096  ],\n       [ 1.486972  , -0.8970178 ],\n       [-1.829543  ,  1.8676547 ],\n       [-2.4276068 ,  2.5640972 ],\n       [-2.923591  ,  2.80229   ],\n       [ 0.8954694 , -0.36594847],\n       [ 2.208579  , -1.3683957 ],\n       [ 1.9458921 , -1.2027872 ],\n       [-2.9546676 ,  2.9020088 ],\n       [-2.6824949 ,  2.7698517 ],\n       [-2.7198958 ,  2.7627153 ],\n       [-2.9929523 ,  2.8448727 ],\n       [ 1.6929828 , -1.0397716 ],\n       [-1.9156351 ,  1.9660888 ],\n       [ 2.2050855 , -1.3520396 ],\n       [-3.1029944 ,  2.7855268 ],\n       [-1.9622682 ,  2.0305288 ],\n       [-2.7110708 ,  2.7890005 ],\n       [ 2.0636704 , -1.2643944 ],\n       [ 2.1515357 , -1.361995  ],\n       [-0.76290846,  0.84767556],\n       [-3.06467   ,  2.7392848 ],\n       [-2.0881581 ,  2.1722445 ],\n       [-3.0679102 ,  2.715463  ],\n       [-3.0462482 ,  2.8391635 ],\n       [-2.8343813 ,  2.8343828 ],\n       [ 1.9974365 , -1.2442005 ],\n       [-2.7049458 ,  2.785723  ],\n       [-3.0997798 ,  2.7772233 ],\n       [ 2.1587737 , -1.345336  ],\n       [-3.079473  ,  2.6466906 ],\n       [ 1.1761359 , -0.73879653],\n       [-2.4704475 ,  2.6189432 ],\n       [-3.072459  ,  2.8042667 ],\n       [-3.083357  ,  2.6817057 ],\n       [ 1.3898909 , -0.8946709 ],\n       [ 2.1531527 , -1.3266737 ],\n       [-3.0692618 ,  2.7021103 ],\n       [ 2.0275545 , -1.2927065 ],\n       [-2.9389765 ,  2.8764858 ],\n       [-3.009513  ,  2.8895428 ],\n       [ 2.1260443 , -1.300998  ],\n       [ 1.3688273 , -0.88896954],\n       [-0.99128085,  1.0610343 ],\n       [ 2.1900532 , -1.3634498 ],\n       [ 2.2812705 , -1.3812172 ],\n       [-0.7274921 ,  0.8625313 ],\n       [ 1.846689  , -1.1452997 ],\n       [-3.0652778 ,  2.7766638 ],\n       [-2.1004128 ,  2.2032473 ],\n       [-3.0683448 ,  2.6063483 ],\n       [-1.9460175 ,  2.0084648 ],\n       [-2.0191233 ,  2.1425104 ],\n       [-2.7221878 ,  2.7449057 ],\n       [-3.0657067 ,  2.7578473 ],\n       [-2.5349598 ,  2.680818  ],\n       [-2.2712893 ,  2.4112382 ],\n       [-2.7495043 ,  2.8443975 ],\n       [-2.5793862 ,  2.6959054 ],\n       [-3.045925  ,  2.8185563 ],\n       [-1.7267295 ,  1.7466438 ],\n       [-1.9436452 ,  2.0134118 ],\n       [-3.0128696 ,  2.88652   ],\n       [-2.9600773 ,  2.9023345 ],\n       [-2.9373565 ,  2.873821  ],\n       [ 2.2230237 , -1.3552202 ],\n       [ 1.4905857 , -0.93749446],\n       [-3.0244336 ,  2.8760655 ],\n       [-3.0687044 ,  2.684479  ],\n       [-3.029036  ,  2.8709958 ],\n       [-2.9956305 ,  2.900857  ],\n       [-0.9534199 ,  0.9679545 ],\n       [-2.683935  ,  2.7709777 ],\n       [ 1.1877949 , -0.65710765],\n       [-3.009142  ,  2.819837  ],\n       [-2.2873452 ,  2.414562  ],\n       [-2.9359806 ,  2.8656752 ],\n       [-1.7944784 ,  1.857349  ],\n       [-2.673152  ,  2.7662034 ],\n       [-2.0945952 ,  2.1437354 ],\n       [-2.3076205 ,  2.4804697 ],\n       [-2.8549795 ,  2.8685586 ],\n       [-2.2024562 ,  2.352719  ],\n       [-2.0585675 ,  2.0993843 ],\n       [-2.9192586 ,  2.8832676 ],\n       [-3.0063596 ,  2.839966  ],\n       [ 1.8419435 , -1.1682724 ],\n       [-2.8824787 ,  2.8085852 ],\n       [-3.0577672 ,  2.6660283 ],\n       [-3.097015  ,  2.6747499 ],\n       [-2.589712  ,  2.716147  ],\n       [ 1.9739785 , -1.2630904 ],\n       [ 2.112956  , -1.2708749 ],\n       [-0.45964184,  0.69808936],\n       [-3.1068833 ,  2.6505635 ],\n       [-2.4842181 ,  2.6124156 ],\n       [ 2.0038748 , -1.2387487 ],\n       [ 2.0412574 , -1.2786038 ],\n       [ 2.0533488 , -1.2601424 ],\n       [ 1.7342285 , -1.0341982 ],\n       [ 0.5532902 , -0.20932767],\n       [-2.2937336 ,  2.4111865 ],\n       [-2.9768615 ,  2.8779657 ],\n       [-0.87649196,  0.94941914],\n       [-3.0983331 ,  2.7661803 ],\n       [-1.5257801 ,  1.4888995 ],\n       [-3.0624437 ,  2.641503  ],\n       [-2.3673918 ,  2.51104   ],\n       [-1.9723809 ,  2.0508983 ],\n       [-1.2615403 ,  1.3110391 ],\n       [ 1.9611427 , -1.1884849 ],\n       [-2.903916  ,  2.8866248 ],\n       [-2.0287263 ,  2.1411874 ],\n       [-3.0371425 ,  2.8522766 ],\n       [-1.9092853 ,  1.9934705 ],\n       [-3.0869918 ,  2.7162697 ],\n       [-2.6901898 ,  2.762218  ],\n       [-3.0548177 ,  2.7984226 ],\n       [-0.8160742 ,  0.8773382 ],\n       [-3.0664253 ,  2.6132092 ],\n       [ 1.5080701 , -0.9471458 ],\n       [-2.449268  ,  2.554713  ],\n       [-2.9477992 ,  2.8986194 ],\n       [ 2.2515864 , -1.3343716 ],\n       [-3.096302  ,  2.757972  ],\n       [-2.3083127 ,  2.4715466 ],\n       [ 2.2533696 , -1.3795224 ],\n       [ 1.8394473 , -1.1251537 ],\n       [-3.0865762 ,  2.696318  ],\n       [-0.8965652 ,  0.9844064 ],\n       [-2.984038  ,  2.8688543 ]], dtype=float32)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 408\n})"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"validation\"]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "{'accuracy': 0.8186274509803921, 'f1': 0.8741496598639455}"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "metric.compute(predictions=preds, references=predictions.label_ids)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions,references=labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\"test-trainer\", evaluation_strategy=\"epoch\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/1377 : < :, Epoch 0.00/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=1377, training_loss=0.3764699909595276, metrics={'train_runtime': 251.8453, 'train_samples_per_second': 43.693, 'train_steps_per_second': 5.468, 'total_flos': 406183858377360.0, 'train_loss': 0.3764699909595276, 'epoch': 3.0})"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
